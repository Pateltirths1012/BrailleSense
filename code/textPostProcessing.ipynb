{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Post Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patel\\OneDrive - Northeastern University\\Robotics\\Assistive Robotics\\Final Project\\BrailleSense\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelWithLMHead,\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Text File\n",
    "\n",
    "### - Removing duplicates\n",
    "\n",
    "### - sorting lines (if they have spatial or logical sequence)\n",
    "\n",
    "### - Merging fragments into sentences or paragraphs\n",
    "\n",
    "### - Handling common OCR errors, like misrecognized characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_line(line):\n",
    "    \"\"\"clean a single line of text by removing unwanted characters.\"\"\"\n",
    "    return re.sub(r\"[^a-zA-Z0-9.,!? ]\", \"\", line.strip())\n",
    "\n",
    "\n",
    "def preprocess_text_file(input_file, output_file):\n",
    "    # preprocess the collected text into clean, deduplicated sentences\n",
    "    with open(input_file, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # extract and clean text\n",
    "    text_lines = [clean_text_line(line.split(\"] \", 1)[-1]) for line in lines]\n",
    "\n",
    "    # remove duplicates and empty lines\n",
    "    unique_lines = list(filter(None, sorted(set(text_lines))))\n",
    "\n",
    "    # save processed lines to the output files\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(\"\\n\".join(unique_lines))\n",
    "\n",
    "    return unique_lines\n",
    "\n",
    "\n",
    "# preprocess_text_file(\"detected_text.txt\", \"final_output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_fragments_with_local_maxima(fragments):\n",
    "    \"\"\"Simple rule-based merging of overlapping fragments.\"\"\"\n",
    "    \"\"\"\n",
    "    Stitch fragments by prioritizing the longest fragments and avoiding redundancy.\n",
    "    \"\"\"\n",
    "\n",
    "    # Group fragments by their starting word\n",
    "    fragment_groups = defaultdict(list)\n",
    "    for fragment in fragments:\n",
    "        starting_word = fragment.split()[0] if fragment else \"\"\n",
    "        fragment_groups[starting_word].append(fragment)\n",
    "\n",
    "    stitched_sentence = []\n",
    "    for _, group in fragment_groups.items():\n",
    "        # Sort fragments in the group by length (descending)\n",
    "        largest_fragment = max(group, key=len)\n",
    "\n",
    "        # Add the largest fragment if it's not redundant\n",
    "        if not any(largest_fragment in stitched for stitched in stitched_sentence):\n",
    "            stitched_sentence.append(largest_fragment)\n",
    "\n",
    "    # Join the selected fragments into a coherent sentence\n",
    "    return \" \".join(stitched_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  The Daily Meditations with Darilyn Amick will feature daily Meditations from around the world . Amick is the author of a book called The Meditations of the World .\n"
     ]
    }
   ],
   "source": [
    "# Example fragments\n",
    "fragments = [\n",
    "    \"ARE HEALED\",\n",
    "    \"ARE HEALED OR\",\n",
    "    \"ARE YOU\",\n",
    "    \"ARE YOU HEALED OR\",\n",
    "    \"JUST ISOLATED WITH NO\",\n",
    "    \"JUST ISOLATED\",\n",
    "    \"ONE TO TRIGGER YOU?\",\n",
    "    \"ONE TO\",\n",
    "]\n",
    "\n",
    "\n",
    "with open(\"final_output.txt\", \"r\") as file:\n",
    "    fragments = file.readlines()\n",
    "\n",
    "\n",
    "final_sentence = merge_fragments_with_local_maxima(fragments)\n",
    "# print(\"Final Sentence:\", final_sentence)\n",
    "\n",
    "summarizer = pipeline(\"summarization\", device=0)\n",
    "\n",
    "summary = summarizer(final_sentence, max_length=52,\n",
    "                     min_length=25, do_sample=False)\n",
    "\n",
    "print(\"Summary:\", summary[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARE', 'HEALED', 'ARE', 'HEALED', 'OR', 'ARE', 'YOU', 'ARE', 'YOU', 'HEALED', 'OR', 'JUST', 'ISOLATED', 'WITH', 'NO', 'JUST', 'ISOLATED', 'ONE', 'TO', 'TRIGGER', 'YOU?', 'ONE', 'TO']\n"
     ]
    }
   ],
   "source": [
    "# Example list of fragments\n",
    "# fragments = [\"ARE HEALED\", \"ARE YOU HEALED\", \"ISOLATED WITH NO\", \"ONE TO TRIGGER YOU?\"]\n",
    "fragments = [\n",
    "    \"ARE HEALED\",\n",
    "    \"ARE HEALED OR\",\n",
    "    \"ARE YOU\",\n",
    "    \"ARE YOU HEALED OR\",\n",
    "    \"JUST ISOLATED WITH NO\",\n",
    "    \"JUST ISOLATED\",\n",
    "    \"ONE TO TRIGGER YOU?\",\n",
    "    \"ONE TO\",\n",
    "]\n",
    "\n",
    "# Flatten and split each fragment into words\n",
    "flattened_list = [word for fragment in fragments for word in fragment.split()]\n",
    "\n",
    "# Print the result\n",
    "print(flattened_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = [\n",
    "    \"ARE HEALED\",\n",
    "    \"ARE HEALED OR\",\n",
    "    \"ARE OR\",\n",
    "    \"ARE YOU\",\n",
    "    \"ARE YOU HEALED\",\n",
    "    \"ARE YOU HEALED OR\",\n",
    "    \"HEALED\",\n",
    "    \"HEALED OR\",\n",
    "    \"HEALEO\",\n",
    "    \"IBOLATED\",\n",
    "    \"ISOLATED\",\n",
    "    \"ISOLATED WITH\",\n",
    "    \"ISOLATED WITH NO\",\n",
    "    \"JUST ISOLATED\",\n",
    "    \"JUST ISOLATED WITH\",\n",
    "    \"JUST ISOLATED WITH NO\",\n",
    "    \"JUST NO\",\n",
    "    \"JUST WITH NO\",\n",
    "    \"ONE TO\",\n",
    "    \"ONE TO TRIGGER\",\n",
    "    \"ONE TO TRIGGER YOU?\",\n",
    "    \"ONE TO YOU?\",\n",
    "    \"ONE TRIGGER YOU?\",\n",
    "    \"ONE YOU?\",\n",
    "    \"TO TRIGGER\",\n",
    "    \"TO TRIGGER YOU?\",\n",
    "    \"TRIGGER\",\n",
    "    \"TRIGGER YOU?\",\n",
    "    \"TRIGOER\",\n",
    "    \"WITH NO\",\n",
    "    \"WITHNG\",\n",
    "    \"WITHNO\",\n",
    "    \"YOU HEALED\",\n",
    "    \"YOU HEALED OR\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fragments = [\n",
    "#     \"ARE HEALED\",\n",
    "#     \"ARE HEALED OR\",\n",
    "#     \"ARE YOU\",\n",
    "#     \"ARE YOU HEALED OR\",\n",
    "#     \"JUST ISOLATED WITH NO\",\n",
    "#     \"JUST ISOLATED\",\n",
    "#     \"ONE TO TRIGGER YOU?\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARE HEALED ARE HEALED OR ARE OR ARE YOU ARE YOU HEALED ARE YOU HEALED OR HEALED HEALED OR HEALEO IBOLATED ISOLATED ISOLATED WITH ISOLATED WITH NO JUST ISOLATED JUST ISOLATED WITH JUST ISOLATED WITH NO JUST NO JUST WITH NO ONE TO ONE TO TRIGGER ONE TO TRIGGER YOU? ONE TO YOU? ONE TRIGGER YOU? ONE YOU? TO TRIGGER TO TRIGGER YOU? TRIGGER TRIGGER YOU? TRIGOER WITH NO WITHNG WITHNO YOU HEALED YOU HEALED OR\n"
     ]
    }
   ],
   "source": [
    "flattened_string = \" \".join(fragments)\n",
    "print(flattened_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "c:\\Users\\patel\\OneDrive - Northeastern University\\Robotics\\Assistive Robotics\\Final Project\\BrailleSense\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1833: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mrm8488/t5-base-finetuned-common_gen\")\n",
    "\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\n",
    "    \"mrm8488/t5-base-finetuned-common_gen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'digging a hole in the ground to plant trees'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_sentence(words, max_length=55):\n",
    "    input_text = words\n",
    "    features = tokenizer([input_text], return_tensors=\"pt\")\n",
    "\n",
    "    output = model.generate(\n",
    "        input_ids=features[\"input_ids\"],\n",
    "        attention_mask=features[\"attention_mask\"],\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "words = \"tree plant ground hole dig\"\n",
    "\n",
    "gen_sentence(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARE HEALED OR YOU HEALEO IBOLATED ISOLATED WITH NO JUST ONE TO TRIGGER YOU? TRIGOER WITHNG WITHNO\n"
     ]
    }
   ],
   "source": [
    "# removing duplicates\n",
    "unique_flattened_string = \" \".join(dict.fromkeys(flattened_string.split()))\n",
    "print(unique_flattened_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARE YOU HEALLED OR YOU ARE ISOLATED WITH NO JUST A TRIGGER TO USE?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_answer = gen_sentence(unique_flattened_string)\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠠⠁⠠⠗⠠⠑ ⠠⠽⠠⠕⠠⠥ ⠠⠓⠠⠑⠠⠁⠠⠇⠠⠇⠠⠑⠠⠙ ⠠⠕⠠⠗ ⠠⠽⠠⠕⠠⠥ ⠠⠁⠠⠗⠠⠑ ⠠⠊⠠⠎⠠⠕⠠⠇⠠⠁⠠⠞⠠⠑⠠⠙ ⠠⠺⠠⠊⠠⠞⠠⠓ ⠠⠝⠠⠕ ⠠⠚⠠⠥⠠⠎⠠⠞ ⠠⠁ ⠠⠞⠠⠗⠠⠊⠠⠛⠠⠛⠠⠑⠠⠗ ⠠⠞⠠⠕ ⠠⠥⠠⠎⠠⠑⠦\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from pybraille import convertText\n",
    "\n",
    "braille_text = convertText(final_answer)\n",
    "print(braille_text)\n",
    "print(type(braille_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
